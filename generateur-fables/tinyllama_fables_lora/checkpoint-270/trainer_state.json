{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 270,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.6591377258300781,
      "learning_rate": 0.00019733333333333335,
      "loss": 2.9937,
      "step": 5
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.5863971710205078,
      "learning_rate": 0.000194,
      "loss": 2.9156,
      "step": 10
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7025444507598877,
      "learning_rate": 0.00019066666666666668,
      "loss": 2.8427,
      "step": 15
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7299289703369141,
      "learning_rate": 0.00018733333333333335,
      "loss": 2.7863,
      "step": 20
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.9337711930274963,
      "learning_rate": 0.00018400000000000003,
      "loss": 2.744,
      "step": 25
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8756117224693298,
      "learning_rate": 0.00018066666666666668,
      "loss": 2.6332,
      "step": 30
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.7702904939651489,
      "learning_rate": 0.00017733333333333335,
      "loss": 2.5893,
      "step": 35
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.6964958310127258,
      "learning_rate": 0.000174,
      "loss": 2.5939,
      "step": 40
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6847838163375854,
      "learning_rate": 0.00017066666666666668,
      "loss": 2.564,
      "step": 45
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.7445110082626343,
      "learning_rate": 0.00016733333333333335,
      "loss": 2.4916,
      "step": 50
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.7566072940826416,
      "learning_rate": 0.000164,
      "loss": 2.4736,
      "step": 55
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.8207353353500366,
      "learning_rate": 0.00016066666666666668,
      "loss": 2.4841,
      "step": 60
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 0.6978439688682556,
      "learning_rate": 0.00015733333333333333,
      "loss": 2.4801,
      "step": 65
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.8496960997581482,
      "learning_rate": 0.000154,
      "loss": 2.432,
      "step": 70
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.8483138680458069,
      "learning_rate": 0.00015066666666666668,
      "loss": 2.4538,
      "step": 75
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.7377256155014038,
      "learning_rate": 0.00014733333333333335,
      "loss": 2.4644,
      "step": 80
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 0.854826033115387,
      "learning_rate": 0.000144,
      "loss": 2.4194,
      "step": 85
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8282889127731323,
      "learning_rate": 0.00014066666666666668,
      "loss": 2.4505,
      "step": 90
    },
    {
      "epoch": 3.1666666666666665,
      "grad_norm": 0.7485252618789673,
      "learning_rate": 0.00013733333333333333,
      "loss": 2.3891,
      "step": 95
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.8426742553710938,
      "learning_rate": 0.000134,
      "loss": 2.4378,
      "step": 100
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.8789653182029724,
      "learning_rate": 0.00013066666666666668,
      "loss": 2.408,
      "step": 105
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.8349403738975525,
      "learning_rate": 0.00012733333333333336,
      "loss": 2.412,
      "step": 110
    },
    {
      "epoch": 3.8333333333333335,
      "grad_norm": 0.8264104127883911,
      "learning_rate": 0.000124,
      "loss": 2.4085,
      "step": 115
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.8454585075378418,
      "learning_rate": 0.00012066666666666668,
      "loss": 2.3814,
      "step": 120
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.8624916672706604,
      "learning_rate": 0.00011733333333333334,
      "loss": 2.3523,
      "step": 125
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.8153189420700073,
      "learning_rate": 0.00011399999999999999,
      "loss": 2.3919,
      "step": 130
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.857541561126709,
      "learning_rate": 0.00011066666666666667,
      "loss": 2.3517,
      "step": 135
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 0.8584951162338257,
      "learning_rate": 0.00010733333333333333,
      "loss": 2.3711,
      "step": 140
    },
    {
      "epoch": 4.833333333333333,
      "grad_norm": 0.8555330634117126,
      "learning_rate": 0.00010400000000000001,
      "loss": 2.3875,
      "step": 145
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0043195486068726,
      "learning_rate": 0.00010066666666666667,
      "loss": 2.4019,
      "step": 150
    },
    {
      "epoch": 5.166666666666667,
      "grad_norm": 0.8559966087341309,
      "learning_rate": 9.733333333333335e-05,
      "loss": 2.3573,
      "step": 155
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 1.0230239629745483,
      "learning_rate": 9.4e-05,
      "loss": 2.3332,
      "step": 160
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.000656247138977,
      "learning_rate": 9.066666666666667e-05,
      "loss": 2.3469,
      "step": 165
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 0.9495258331298828,
      "learning_rate": 8.733333333333333e-05,
      "loss": 2.3677,
      "step": 170
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 0.9377400279045105,
      "learning_rate": 8.4e-05,
      "loss": 2.3676,
      "step": 175
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.9326403737068176,
      "learning_rate": 8.066666666666667e-05,
      "loss": 2.3495,
      "step": 180
    },
    {
      "epoch": 6.166666666666667,
      "grad_norm": 0.945585310459137,
      "learning_rate": 7.733333333333333e-05,
      "loss": 2.3185,
      "step": 185
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 1.0375078916549683,
      "learning_rate": 7.4e-05,
      "loss": 2.3369,
      "step": 190
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.1435140371322632,
      "learning_rate": 7.066666666666667e-05,
      "loss": 2.3183,
      "step": 195
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.9430572390556335,
      "learning_rate": 6.733333333333333e-05,
      "loss": 2.3096,
      "step": 200
    },
    {
      "epoch": 6.833333333333333,
      "grad_norm": 0.9035631418228149,
      "learning_rate": 6.400000000000001e-05,
      "loss": 2.3468,
      "step": 205
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.0079553127288818,
      "learning_rate": 6.066666666666667e-05,
      "loss": 2.3895,
      "step": 210
    },
    {
      "epoch": 7.166666666666667,
      "grad_norm": 0.9503201246261597,
      "learning_rate": 5.7333333333333336e-05,
      "loss": 2.3585,
      "step": 215
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 1.0245742797851562,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 2.3244,
      "step": 220
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.0262832641601562,
      "learning_rate": 5.0666666666666674e-05,
      "loss": 2.2936,
      "step": 225
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 1.0433685779571533,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.309,
      "step": 230
    },
    {
      "epoch": 7.833333333333333,
      "grad_norm": 0.9497131705284119,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.3177,
      "step": 235
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.0467581748962402,
      "learning_rate": 4.066666666666667e-05,
      "loss": 2.3339,
      "step": 240
    },
    {
      "epoch": 8.166666666666666,
      "grad_norm": 0.9621506929397583,
      "learning_rate": 3.733333333333334e-05,
      "loss": 2.2945,
      "step": 245
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.9938561916351318,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 2.324,
      "step": 250
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.0438700914382935,
      "learning_rate": 3.066666666666667e-05,
      "loss": 2.3268,
      "step": 255
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 1.0498942136764526,
      "learning_rate": 2.733333333333333e-05,
      "loss": 2.298,
      "step": 260
    },
    {
      "epoch": 8.833333333333334,
      "grad_norm": 1.038802981376648,
      "learning_rate": 2.4e-05,
      "loss": 2.3312,
      "step": 265
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.0258997678756714,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 2.2986,
      "step": 270
    }
  ],
  "logging_steps": 5,
  "max_steps": 300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6826640885268480.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
